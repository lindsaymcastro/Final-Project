---
title: "Final Project"
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: show
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```


Libraries Used for this Project
```{r,message=FALSE, warning=FALSE}
library(readr)
library(tidyverse)
library(tidymodels)
library(ISLR)
library(rpart.plot)
library(vip)
library(janitor)
library(xgboost)
library(ISLR2) 
library(discrim)
library(poissonreg)
library(corrr)
library(corrplot)
library(klaR) 
library(pROC)
library(glmnet)
library(dplyr)
library(randomForest)
library(rpart)
library(ranger)
library(vip)
library(lubridate)
library(kernlab)
library(kknn)
tidymodels_prefer()
```


Read the data file into R. This file was a csv file.
```{r}
sneakers <- read.csv("Data/StockX-Data.csv")
```


### Cleaning the Data
Next we will do some cleaning. After reading the file in I noticed that there were certain variables that were read in as characters, however they will need to be used as integers therefore we will be converting them to integers before we continue. Likewise the dates that are provided were read in as characters and we will have to switch them to be read as a date format.
```{r}
# Clean names
sneakers <- sneakers %>%
  clean_names()

#Sale.Price from chr to int
sneakers$sale_price <- parse_number(sneakers$sale_price)
sneakers$sale_price <- as.integer(sneakers$sale_price)

# Retail.Price from chr to int
sneakers$retail_price <- parse_number(sneakers$retail_price)
sneakers$retail_price <- as.integer(sneakers$retail_price)

# Order.Date from chr to date
sneakers$order_date <- as.Date(sneakers$order_date, "%m/%d/%y")

# Release.Date from chr to date
sneakers$release_date <- as.Date(sneakers$release_date, "%m/%d/%y")

#Check for Missing Values in the dataset
sum(is.na(sneakers))
```

There are no missing values within the data set, therefore we will continue to use the entire data set. 

### Adding additional information for further analysis
```{r}
# Add the number of weeks between the release date and the order date
sneakers$weeks <- round(difftime(sneakers$order_date, sneakers$release_date, units = "weeks"))

# Add in the day of the week that the shoe was ordered/purchased
sneakers$day_of_week <- format(as.Date(sneakers$order_date), "%A")

# Add how much profit was made on each sale
sneakers$profit <- sneakers$sale_price - sneakers$retail_price

# Add the percentage of the profit made
sneakers$profit_perc <- round((sneakers$profit / sneakers$retail_price) * 100)
```


### Exploratory Data Analysis (EDA)

```{r}
sneakers %>%
  summary()

sneakers %>%
  count(shoe_size) %>%
  arrange(-n) %>%
  head()
```


Shoe Size
There are 26 different shoe sizes in the dataset. The top three sizes across the entire data set are:
* 10 (11093) 
* 9 (9706) 
* 11 (9251) 


```{r}
sneakers %>%
  select(brand) %>%
  distinct() %>%
  group_by() %>%
  head()
```

There are only two brands within the 99,956 different observations found in this dataset: Yeezy and Off-White.



Next we will be separating the two brands into their own data frames to be able to analyze them separately.
```{r}
# Create a new data frame for all the Off-White brand sneakers
offwhite <- sneakers %>%
  select(order_date, brand, sneaker_name, sale_price, retail_price, release_date, shoe_size, buyer_region, weeks, day_of_week, profit, profit_perc) %>%
  filter(brand == "Off-White")

# Summary of the data fram
offwhite %>%
  summary()

offwhite %>%
  count(shoe_size) %>%
  arrange(-n) %>%
  head()
```
This Off-White dataset is missing the size 13.0 and 14.5, therefore there are only 24 sizes as opposed to 26. The top three sizes with the most shoes for Off-White are: 
* 10 (3654) 
* 11 (3109) 
* 9 (2703) 


```{r}
# Yeezy dataframe

# Clean brand names to not include spaces
sneakers$brand <- gsub(" ", "", sneakers$brand)

# Create a new data frame for all the Yeezy brand sneakers
yeezy <- sneakers %>%
  select(order_date, brand, sneaker_name, sale_price, retail_price, release_date, shoe_size, buyer_region, weeks, day_of_week, profit, profit_perc) %>%
  filter(brand == "Yeezy")

# Sumamry of the data frame
yeezy %>%
  summary()

yeezy %>%
  count(shoe_size) %>%
  arrange(-n) %>%
  head()
```
This Yeezy dataset is missing the size 15, therefore there are only 25 sizes as opposed to 26. The top three sizes with the most shoes for Yeezy are: 
* 10 (7439) 
* 9 (7003) 
* 9.5 (6430) 


Within each brand there are different types of sneakers. Next we will look through each of the dataframes for both brands to see how many individual sneakers there are.
```{r}
#Find the number of sneakers listed for Off-White and the quantities of each.
offwhite %>%
  count(sneaker_name) %>%
  arrange(-n)%>%
  head()
```

For the Off-White brand there are 30 individual sneaker types, where the sneakers with the most sales are: 
* Air-Jordan-1-Retro-High-Off-White-University-Blue (4635) 
* Nike-Air-Presto-Off-White-Back-2018 (1884) 
* Nike-Air-Presto-Off-White-White-2018 (1883) 

```{r}
#Find the number of sneakers listed for Yeezy and the quantities of each.
yeezy %>%
  count(sneaker_name) %>%
  arrange(-n) %>%
  head()
```

For the Yeezy brand there are 20 individual sneaker types, where the sneakers with the most sales are: 
* Adidas-Yeezy-Boost-350-V2-Butter (11423) 
* Adidas-Yeezy-Boost-350-V2-Beluga-2pt0 (10395) 
* Adidas-Yeezy-Boost-350-V2-Zebra (10110) 


In total there are 50 different kinds of sneakers across 2 different brands, 30 for Off-White, and 20 for Yeezy. 



```{r}
# Find average sale and retail price and max sale price for each sneaker, arranged by highest average sale price to lowest
offwhite %>%
  group_by(sneaker_name) %>%
  summarize(avg_retail_price=mean(retail_price), avg_sale_price=mean(sale_price), max_sale_price=max(sale_price)) %>%
  arrange(-avg_sale_price) %>%
  head()
```

The most expensive sales for Off-White shoes are:
* Air-Jordan-1-Retro-High-Off-White-Chicago (4050) 
* Air-Jordan-1-Retro-High-Off-White-University-Blue (3680) 
* Air-Jordan-1-Retro-High-Off-White-White (2950) 


The most expensive Off-White shoes on average for sales price are:
* Air-Jordan-1-Retro-High-Off-White-White (1826.07) 
* Air-Jordan-1-Retro-High-Off-White-Chicago (1769)
* Nike-Air-Presto-Off-White (1236.05) 


```{r}
# Find average sale and retail price and max sale price for each sneaker, arranged by highest average sale price to lowest
yeezy %>%
  group_by(sneaker_name) %>%
  summarize(avg_retail_price=mean(retail_price), avg_sale_price=mean(sale_price), max_sale_price=max(sale_price)) %>%
  arrange(-avg_sale_price) %>%
  head()
```

The most expenisive sales for Yeezy shoes are: 
* Adidas-Yeezy-Boost-350-Low-Turtledove (2300) 
* Adidas-Yeezy-Boost-350-Low-Moonrock (2000) 
* Adidas-Yeezy-Boost-350-V2-Blue-Tint (2000) 

The most expensive Yeezy shoes on average for sales price are:
* Adidas-Yeezy-Boost-350-Low-Turtledove (1531.66) 
* Adidas-Yeezy-Boost-350-Low-Oxford-Tan (1011.51) 
* Adidas-Yeezy-Boost-350-Low-Moonrock (996.71) 


Next we will find out how many buyer regions there are and what are they:
```{r}
sneakers %>% 
  count(buyer_region) %>%
  arrange(-n) %>%
  head()
```

There are a total of 51 regions where the shoes in the data set was sold, where the top regions with the most sales are: 
* California (19349) 
* New York (16525) 
* Oregon (7681) 


The regions for the most part are states, however District of Colombia is considered a region in this data set, which is not a state but rather the capital of the U.S.




Total sales per sneaker (useful)
```{r}
sneakers %>%
  count(sneaker_name) %>%
  mutate(sneaker_name = fct_reorder(sneaker_name, n)) %>%
  ggplot(aes(sneaker_name, n)) + 
  geom_col(fill = "limegreen") + 
  labs(title = "Total Sales Per Sneaker", x = "Sneaker Name", y = "Number of Shoes") + 
  coord_flip()
```
Total sales per state (number of shoes) (useful)
```{r}
sneakers %>%
  group_by(buyer_region) %>%
  count() %>%
  ggplot(aes(reorder(buyer_region, n), n)) + 
  geom_col(fill = "limegreen") + 
  labs(title = "Total Number of Shoes Sold Per State", x = "State", y = "Number of Shoes") + 
  coord_flip()
```

Total sales per state (sum of money) (useful)
```{r}
sneakers %>%
  group_by(buyer_region) %>%
  summarise(total_purchased = sum(sale_price)) %>%
  ggplot(aes(reorder(buyer_region, total_purchased), total_purchased)) + 
  geom_col(fill = "limegreen") + 
  scale_y_continuous(labels = scales::dollar_format()) + 
  labs(title = "Total Sales Per State", x = "State", y = "Total in Sales (Dollars)") + 
  coord_flip()
```
Average sale price per state (useful)
```{r}
sneakers %>%
  group_by(buyer_region) %>%
  summarise(avg_purchased = mean(sale_price)) %>% 
  ggplot(aes(reorder(buyer_region, avg_purchased), avg_purchased)) + 
  geom_col(fill = "limegreen") + 
  scale_y_continuous(labels = scales::dollar_format()) + 
  labs(title = "Average Sale Price Per State", x = "State", y = "Average Shoe Price (Dollar)") + 
  coord_flip()
```

Profit by Sneakers (percent and amount)
```{r}
sneakers %>%
  group_by(sneaker_name) %>%
  summarise(avg_profit = round(mean(profit))) %>%
  ggplot(aes(reorder(sneaker_name, avg_profit), avg_profit)) +
  geom_col(fill = "limegreen") +
  scale_y_continuous(labels = scales::dollar_format()) +
  labs(title = "Average Profit Per Sneaker", x = "Sneaker", y = "Average Profit") +
  coord_flip()

sneakers %>%
  group_by(sneaker_name) %>%
  summarise(avg_profit_perc = round(mean(profit_perc))) %>%
  ggplot(aes(reorder(sneaker_name, avg_profit_perc), avg_profit_perc)) +
  geom_col(fill = "limegreen") +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  labs(title = "Average Profit Percentage Per Sneaker", x = "Sneaker", y = "Average Percent of Profit") + 
  coord_flip()
```


Average shoe size by state (useful)
```{r}
sneakers %>%
  select(buyer_region, shoe_size) %>%
  group_by(buyer_region) %>%
  summarise(avg_shoe_size = mean(shoe_size)) %>%
  ggplot(aes(reorder(buyer_region, avg_shoe_size), avg_shoe_size)) +
  geom_point(color = "limegreen") + 
  labs(title = "Average Shoe Size by State", x = "State", y = "Average Shoe Size") +
  coord_flip()
```
Total number of sales per shoe size (useful)
```{r}
sneakers %>%
  group_by(shoe_size) %>%
  count() %>%
  ggplot(aes(shoe_size, n)) + 
  geom_point(color = "limegreen", size = 3) + 
  scale_x_continuous(breaks = 3:17) + 
  labs(title = "Total Number of Sales Per Shoe Size", x = "Shoe Size", y = "Number of Sales")
```
Shoe size with the most percent profit (useful)
```{r}
sneakers %>%
  select(shoe_size, profit_perc) %>%
  group_by(shoe_size) %>%
  ggplot(aes(x = shoe_size, y = profit_perc)) +
  geom_point(color = "limegreen") + 
  scale_x_continuous(breaks = 3:17) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  labs(title = "Total Profit Percent Per Shoe Size", x = "Shoe Size", y = "Percent of Profit")
```
Average profit percent per shoe size (useful)
```{r}
sneakers %>%
  select(shoe_size, profit_perc) %>%
  group_by(shoe_size) %>%
  summarise(avg_profit_perc = round(mean(profit_perc))) %>%
  ggplot(aes(x = shoe_size, y = avg_profit_perc)) +
  geom_col(fill = "limegreen") + 
  scale_x_continuous(breaks = 3:17) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  labs(title = "Average Profit Percent Per Shoe Size", x = "Shoe Size", y = "Average Percent of Profit")
```
Average sale price per shoe size (useful)
```{r}
sneakers %>% 
  select(shoe_size, sale_price) %>%
  group_by(shoe_size) %>%
  summarise(avg_sale_price = round(mean(sale_price))) %>%
  ggplot(aes(x = shoe_size, y = avg_sale_price)) + 
  geom_col(fill = "limegreen") +
  scale_x_continuous(breaks = 3:17) + 
  scale_y_continuous(labels = scales::dollar_format()) + 
  labs(title = "Average Sale Price Per Shoe Size", x = "Shoe Size", y ="Average Sale Price")
```

when were shoes sold for a loss (might be useful)
```{r}
sneakers %>%
  filter(sale_price < retail_price) %>%
  ggplot(aes(x = as.numeric(weeks), y = profit_perc)) +
  geom_point(color = "limegreen") +
  scale_y_continuous(labels = function(x) paste0(x, "%")) +
  labs(title = "Weeks when Shoes Sold For a Loss", x = "Weeks", y = "Percent of Profit")
```
when were shoes sold for most profit (useful)
```{r}
sneakers %>%
  ggplot(aes(x = as.numeric(weeks), y = profit_perc, color = factor(brand))) +
  geom_point() +
  scale_colour_manual(values = c("#7CFC00", "#228B22")) +
  scale_y_continuous(labels = function(x) paste0(x, "%")) + 
  labs(title = "Weeks when Shoes Sold for Most Profit", x = "Weeks", y = "Percent of Profit")
```
when were most shoes sold (useful)
```{r}
sneakers %>%
  group_by(weeks) %>%
  count() %>%
  ggplot(aes(as.numeric(weeks), n)) + 
  geom_point(color = "limegreen", size = 3) +
  labs(title = "Weeks when the Most Shoes Were Sold", x = "Weeks", y = "Number of Shoes")
```
which day of the week sells most shoes (useful)
```{r}
sneakers %>%
  group_by(day_of_week) %>%
  count() %>%
  ggplot(aes(reorder(day_of_week, n), n)) +
  geom_col(fill = "limegreen") +
  labs(title = "Number of Shoes Sold Per Weekday", x = "Weekday", y = "Number of Shoes") + 
  coord_flip()
```
which day of week sells for most average profit (useful)

```{r}
sneakers %>%
  group_by(day_of_week) %>%
  summarise(avg_profit_perc = round(mean(profit_perc))) %>% 
  ggplot(aes(reorder(x = day_of_week, avg_profit_perc), y = avg_profit_perc)) + 
  geom_col(fill = "limegreen") +
  labs(title = "Average Profit Percent per Weekday", x = "Weekday", y = "Average Percent of Profit") +
  coord_flip()
```



### Data Splitting 
```{r}
#Convert variables to factors
sneakers$brand <- as.factor(sneakers$brand)
sneakers$sneaker_name <- as.factor(sneakers$sneaker_name)
# sneakers$shoe_size <- as.factor(sneakers$shoe_size)
sneakers$buyer_region <- as.factor(sneakers$buyer_region)
sneakers$day_of_week <- as.factor(sneakers$day_of_week)
sneakers$weeks <- as.numeric(sneakers$weeks)
```


Next we split the data and stratify it. Afterwards the split data will be assigned as training or testing. And before creating the recipe, I will fold my training data into 10 folds, with 5 repeats.

```{r}
set.seed(0714)

# Split the data 
sneakers_split <- initial_split(sneakers, strata = profit_perc, prop = 0.7)

# Assign the training and testing data
sneakers_train <- training(sneakers_split)
sneakers_test <- testing(sneakers_split)

# V-fold cross validation
sneakers_fold <- vfold_cv(sneakers_train, strata = profit_perc, v = 10, repeats = 5)

sneakers_train2 <- sneakers_train[,sapply(sneakers_train, is.numeric)]
sneakers_train2 %>%
  cor() %>%
  corrplot(type = "lower", diag = FALSE,
           method = 'color', addCoef.col = "Black")

head(sneakers_train)

```


Finally, we will create our recipe that will be predicting the profit percentage of the shoe sales, given the variables seen in the code below.
```{r}
sneakers_recipe <- recipe(
  # predict the profit percent using all the predictors except, profit, release_date, order_date.
  # weeks will account for the dates that are not being included
  # will use the training data set for this recipe
  profit_perc ~ brand + sneaker_name + retail_price + buyer_region + shoe_size + weeks + day_of_week, data = sneakers_train) %>%
  # dummy code all the variables
  step_dummy(all_nominal_predictors()) %>%
  # scale and center all the predictor variables
  step_normalize(all_predictors())
```

### Modeling

#### Linear Regression Model 
```{r, warning=FALSE}
# Create the model
lm_model <- linear_reg() %>%
  set_engine("lm")

# Create the workflow
lm_wf <- workflow() %>%
  add_model(lm_model) %>%
  add_recipe(sneakers_recipe)

# Fit model to training set
lm_fit <- fit(lm_wf, sneakers_train)

# View the results (don't really need)
lm_fit %>%
  extract_fit_parsnip() %>%
  tidy()

# Table w/ predicted and actual values
sneakers_train_res <- predict(lm_fit, new_data = sneakers_train %>% select(-profit_perc))

sneakers_train_res <- bind_cols(sneakers_train_res, sneakers_train %>% select(profit_perc))
sneakers_train_res %>%
  head()

# Metric Set w/ RMSE, MSE, R^2
sneakers_metrics <- metric_set(rmse, rsq, mae)
sneakers_metrics(sneakers_train_res, truth = profit_perc, 
                 estimate = .pred)

# Plot for Predicted vs Actual Values
sneakers_train_res %>%
  ggplot(aes(x = .pred, y = profit_perc)) +
  geom_point(alpha = 0.2) +
  geom_abline(lty = 2) +
  theme_bw() +
  coord_obs_pred()
```


#### Decision Tree 
```{r, message=FALSE}
# Create the model
reg_tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("regression")

# Create the workflow
reg_tree_wf <- workflow() %>%
  add_model(reg_tree_spec %>% set_args(cost_complexity = tune())) %>%
  add_recipe(sneakers_recipe)

param_grid_dt <- grid_regular(cost_complexity(range = c(-4, -1)), levels = 10)

tune_res_dt <- tune_grid(
  reg_tree_wf, 
  resamples = sneakers_fold, 
  grid = param_grid_dt,
  control = control_grid(verbose = TRUE)
)

autoplot(tune_res_dt)


```

```{r}
best_complexity <-select_best(tune_res_dt, metric = "rmse")

reg_tree_final <- finalize_workflow(reg_tree_wf, best_complexity)

reg_tree_final_fit <- fit(reg_tree_final, data = sneakers_train)

reg_tree_final_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE)

collect_metrics(tune_res_dt)%>%
  arrange(std_err)

best_complexity
```


### Random Forest 
```{r}

```





### Ridge Regression 
```{r,message=FALSE, warning=FALSE}
# Create a model
ridge_spec <- 
  linear_reg(penalty = tune(), mixture = 0) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

# Create a workflow 
ridge_wf <- workflow() %>%
  add_recipe(sneakers_recipe) %>%
  add_model(ridge_spec)

penalty_grid_r <- grid_regular(penalty(range = c(-5, 5)), levels = 50)
penalty_grid_r

tune_res_ridge <- tune_grid(
  ridge_wf, 
  resamples = sneakers_fold, 
  grid = penalty_grid_r,
  control = control_grid(verbose = TRUE)
)

autoplot(tune_res_ridge)

```

```{r}
collect_metrics(tune_res_ridge)

best_penalty_r <- select_best(tune_res_ridge, metric = "rsq")
best_penalty_r

ridge_final <- finalize_workflow(ridge_wf, best_penalty_r)

ridge_final_fit <- fit(ridge_final, data = sneakers_train)

```




### Lasso Regression
```{r,message=FALSE, warning=FALSE}
# Create the model
lasso_spec <- 
  linear_reg(penalty = tune(), mixture = 1) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

# Create the workflow 
lasso_wf <- workflow() %>%
  add_recipe(sneakers_recipe) %>%
  add_model(lasso_spec)

penalty_grid_l <- grid_regular(penalty(range = c(-2, 2)), levels = 50)

tune_res_lasso <- tune_grid(
  lasso_wf, 
  resamples = sneakers_fold, 
  grid = penalty_grid_l,
  control = control_grid(verbose = TRUE)
)

autoplot(tune_res_lasso)
```

```{r}
collect_metrics(tune_res_lasso)

best_penalty_l <- select_best(tune_res_lasso, metric = "rsq")
best_penalty_l

lasso_final <- finalize_workflow(lasso_wf, best_penalty_l)

lasso_final_fit <- fit(lasso_final, data = sneakers_train)

```


### Nearest Neighbors 
```{r}
# Create the model 
knn_model <- nearest_neighbor(
  neighbors = tune(),
  mode = "regression") %>%
  set_engine("kknn")

# Create the workflow 
knn_wf <- workflow() %>%
  add_model(knn_model) %>%
  add_recipe(sneakers_recipe)

# Set-up tuning grid
knn_params <- parameters(knn_model)

# Define grid
knn_grid <- grid_regular(knn_params, levels = 2)

# Tune the grid
knn_tune <- knn_wf %>%
  tune_grid(
    resamples = sneakers_fold,
    grid = knn_grid,
    control = control_grid(verbose = TRUE)
)

autoplot(knn_tune, metric = "rmse")




```

```{r}
collect_metrics(knn_tune)

best_knn <- select_best(knn_tune, metric = "rsq")

knn_final <- finalize_workflow(knn_wf, best_knn)

knn_final_fit <- fit(knn_final, data = sneakers_train)
```























